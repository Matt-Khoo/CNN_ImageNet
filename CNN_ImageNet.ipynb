{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\"> File Information</span>\n",
    "***\n",
    "File: **CNN_ImageNet.ipynb**  <br/>\n",
    "Author: **Matthew Khoo**  <br/>\n",
    "Last Updated: **23/07/2020**    <br/>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Convolutional Neural Networks (CNN) for Image Classification </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import modules\n",
    "from modules import SimplePreprocessor, AnimalsDatasetManager, DefaultModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Image Data Preprocessing </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from dataset directory\n",
    "def create_label_folder_dict(adir):\n",
    "    sub_folders= [folder for folder in os.listdir(adir)\n",
    "                  if os.path.isdir(os.path.join(adir, folder))]\n",
    "    label_folder_dict= dict()\n",
    "    for folder in sub_folders:\n",
    "        item= {folder: os.path.abspath(os.path.join(adir, folder))}\n",
    "        label_folder_dict.update(item)\n",
    "    return label_folder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder_dict= create_label_folder_dict(\"./datasets/Animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SimplePreprocessor(width=32, height=32)\n",
    "data_manager = AnimalsDatasetManager([sp])\n",
    "data_manager.load(label_folder_dict, verbose=100)\n",
    "data_manager.process_data_label()\n",
    "data_manager.train_valid_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_manager.X_train.shape, data_manager.y_train.shape)\n",
    "print(data_manager.X_valid.shape, data_manager.y_valid.shape)\n",
    "print(data_manager.X_test.shape, data_manager.y_test.shape)\n",
    "print(data_manager.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Default Model Use Example </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = DefaultModel(name='network1',\n",
    "                       num_classes=len(data_manager.classes),\n",
    "                       optimizer='sgd',\n",
    "                       batch_size= 128,\n",
    "                       num_epochs = 20,\n",
    "                       learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and display summary of the model\n",
    "network1.build_cnn()\n",
    "network1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with training data\n",
    "network1.fit(data_manager, batch_size = 64, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy of trained model against the test data\n",
    "network1.compute_accuracy(data_manager.X_test, data_manager.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model's training progress\n",
    "network1.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for example test set\n",
    "network1.predict(data_manager.X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results of prediction for several images\n",
    "network1.plot_prediction(data_manager.X_test, data_manager.y_test, data_manager.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Default Model Experiment with Varying Learning Rates</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_models = []\n",
    "learningRates = [0.0001,0.001,0.005,0.01, 0.1] \n",
    "for i in range (len(learningRates)):\n",
    "    # Other parameters are the same as the default model\n",
    "    temp = DefaultModel(name='network'+str(i),\n",
    "                       num_classes=len(data_manager.classes),\n",
    "                       optimizer='sgd',\n",
    "                       batch_size= 128,\n",
    "                       num_epochs = 20,\n",
    "                       learning_rate=learningRates[i])\n",
    "    vanilla_models.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for network in vanilla_models:\n",
    "    print(\"Learning rate of\", str(learningRates[j]))\n",
    "    network.build_cnn()\n",
    "    network.fit(data_manager, batch_size = 64, num_epochs = 20)\n",
    "    j += 1\n",
    "    network.plot_progress()\n",
    "    print(\"\\n Next \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Improving the Default Model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Override the architecture of the default model with an improved model.\n",
    "    Accommodate data augmentation in fitting the model.\n",
    "    Implementation using blocks of n to fit the model.layers. \n",
    "    Block layers pattern [conv, batch norm, activation, conv, batch norm, activation, mean pool, dropout]\n",
    "\"\"\"\n",
    "class MyModel(DefaultModel):\n",
    "    def __init__(self,\n",
    "                 name='network1',\n",
    "                 width=32, height=32, depth=3,\n",
    "                 num_blocks=2,\n",
    "                 feature_maps=32,\n",
    "                 num_classes=4, \n",
    "                 drop_rate=0.2,\n",
    "                 batch_norm = None,\n",
    "                 is_augmentation = False,\n",
    "                 activation_func='relu',\n",
    "                 optimizer='adam',\n",
    "                 batch_size=10,\n",
    "                 num_epochs= 20,\n",
    "                 learning_rate=0.0001,\n",
    "                 verbose= True):\n",
    "        super(MyModel, self).__init__(name, width, height, depth, num_blocks, feature_maps, num_classes, drop_rate, batch_norm, is_augmentation, \n",
    "                                        activation_func, optimizer, batch_size, num_epochs, learning_rate, verbose)\n",
    "        \n",
    "    def get_sub_block(self, first, current_block):\n",
    "        layersArr = []\n",
    "        numFilters = self.feature_maps[current_block]\n",
    "        #print(numFilters)\n",
    "        if first:\n",
    "            conv = layers.Conv2D(numFilters, (3,3), strides = (1,1), padding='same', \n",
    "                               activation=self.activation_func, input_shape = (32,32,3))   # conv\n",
    "        else:  # The following conv layers does not need starting input shape\n",
    "            conv = layers.Conv2D(numFilters, (3,3), strides = (1,1), padding='same', \n",
    "                               activation=self.activation_func)   # conv\n",
    "            \n",
    "        batchNorm = layers.BatchNormalization()   # batch_norm\n",
    "        activation = layers.Activation(self.activation_func)   # activation\n",
    "        layersArr.append(conv)\n",
    "        if self.batch_norm != None:   # only add this layer if attribute self.batch_norm is not None\n",
    "            layersArr.append(batchNorm)\n",
    "        layersArr.append(activation)\n",
    "        return layersArr\n",
    "    \n",
    "    def build_cnn(self):\n",
    "        #self.model = models.Sequential()\n",
    "        first = True\n",
    "        for i in range (self.num_blocks):\n",
    "            # Layers for one block according to the described pattern\n",
    "            # two sub-blocks of [conv, batch_norm, activation] where applicable\n",
    "            for _ in range(2):\n",
    "                for layer in self.get_sub_block(first, i):\n",
    "                    self.model.add(layer)\n",
    "                first = False\n",
    "                  \n",
    "            self.model.add(layers.AveragePooling2D(pool_size=(2,2), strides = (2,2), padding='same'))   # mean pool\n",
    "            if self.drop_rate > 0.0:\n",
    "                self.model.add(layers.Dropout(self.drop_rate))   #dropout\n",
    "                \n",
    "        # Copied from modules.py\n",
    "        self.model.add(layers.Flatten())\n",
    "        self.model.add(layers.Dense(self.num_classes, activation='softmax'))   #softmax \n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, data_manager, batch_size=None, num_epochs=None):\n",
    "        batch_size = self.batch_size if batch_size is None else batch_size\n",
    "        num_epochs = self.num_epochs if num_epochs is None else num_epochs\n",
    "        \n",
    "        # The augmentations done on each image\n",
    "        data_aug = ImageDataGenerator(rotation_range = 15,\n",
    "                                      width_shift_range = 0.15,\n",
    "                                      height_shift_range = 0.15,\n",
    "                                      shear_range = 0.15,\n",
    "                                      zoom_range = 0.15,\n",
    "                                      horizontal_flip = True,\n",
    "                                      fill_mode = 'nearest'\n",
    "                                      )\n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Fitting with or without data augmentation generator\n",
    "        if self.is_augmentation:\n",
    "            self.history = self.model.fit_generator(data_aug.flow(x = data_manager.X_train, \n",
    "                                                                  y = data_manager.y_train, \n",
    "                                                                  batch_size = batch_size),\n",
    "                                                    validation_data = (data_manager.X_valid, data_manager.y_valid), \n",
    "                                                    epochs = num_epochs, verbose= self.verbose)\n",
    "        else:\n",
    "            self.history = self.model.fit(x = data_manager.X_train, y = data_manager.y_train, \n",
    "                                          validation_data = (data_manager.X_valid, data_manager.y_valid), \n",
    "                                          epochs = num_epochs, batch_size = batch_size, verbose= self.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model with no drop rate (and also no batch normalization) as benchmark purposes\n",
    "no_drop_out_network = MyModel(name='network1',\n",
    "                     feature_maps=32,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=4,\n",
    "                     drop_rate= 0.0, # enter your final dropout rate value here\n",
    "                     batch_norm=None,     \n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.001)\n",
    "no_drop_out_network.build_cnn()\n",
    "no_drop_out_network.fit(data_manager)   # default batch size of 10 and epochs of 20 as defined in MyModel\n",
    "no_drop_out_network.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Experiment 1: Dropout Rates </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model with different drop rates using the new model\n",
    "drop_models = []\n",
    "dropRates = [0.2, 0.3, 0.4, 0.5] \n",
    "for i in range (len(dropRates)):\n",
    "    # Other parameters are the same as cell above\n",
    "    drop_temp = MyModel(name='dropout_network'+str(i),\n",
    "                     feature_maps=32,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=4,\n",
    "                     drop_rate= dropRates[i], # enter your final dropout rate value here\n",
    "                     batch_norm=None,     \n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.001)\n",
    "    drop_models.append(drop_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for network in drop_models:\n",
    "    print(\"Drop rate of\", str(dropRates[j]))\n",
    "    network.build_cnn()\n",
    "    network.fit(data_manager)   # default batch size of 10 and epochs of 20 as defined in MyModel\n",
    "    j += 1\n",
    "    network.plot_progress()\n",
    "    print(\"\\n Next \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Experiment 2: Batch Normalization </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm_network = MyModel(name='batch_norm_network',\n",
    "                     feature_maps=32,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=4,\n",
    "                     drop_rate= 0, \n",
    "                     batch_norm=True, #do batch norm    \n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.01)\n",
    "batch_norm_network.build_cnn()\n",
    "batch_norm_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm_network.fit(data_manager)   # default batch size of 10 and epochs of 20 as defined in MyModel\n",
    "batch_norm_network.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Experiment 3: Hyperparameter Tuning </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters for fast training and best accuracy\n",
    "# Arguably best model configurations\n",
    "bestModel = MyModel(name='network_best',\n",
    "                     feature_maps=16,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=3,\n",
    "                     drop_rate= 0.23,  \n",
    "                     batch_norm=None,    \n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.0003)\n",
    "bestModel.build_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel.fit(data_manager, batch_size = 16)\n",
    "bestModel.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Experiment 4: Data Augmentation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_network = MyModel(name='aug_network',\n",
    "                     feature_maps=16,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=3,\n",
    "                     drop_rate= 0.23, # keep_prob = 1- 0.23\n",
    "                     batch_norm=None,\n",
    "                     is_augmentation= True,\n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.0003)\n",
    "augmentation_network.build_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_network.fit(data_manager, batch_size = 16)\n",
    "augmentation_network.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Adversial Attacks PGD and FGM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cleverhans\n",
    "from cleverhans.future.tf2.attacks import projected_gradient_descent, fast_gradient_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images and their labels\n",
    "def plot_images(row, col, images, labels):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize = (2 * col, 2 * row))\n",
    "    for i in range(row*col):\n",
    "        plt.subplot(row, col, i + 1)\n",
    "        plt.imshow((images[i] + 1.0)/2)\n",
    "        plt.xlabel(labels[i])\n",
    "        plt.grid(False)\n",
    "        plt.tick_params(axis = \"x\", which = \"both\", bottom = False, labelbottom = False)  # remove x_tick\n",
    "        plt.tick_params(axis = \"y\", which = \"both\", left = False, labelleft = False)    # remove y_tick\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = MyModel(name='network_attack',\n",
    "                     feature_maps=16,\n",
    "                     num_classes=len(data_manager.classes),\n",
    "                     num_blocks=3,\n",
    "                     drop_rate= 0.23, # keep_prob = 1- 0.23\n",
    "                     batch_norm=None,\n",
    "                     is_augmentation= True,\n",
    "                     optimizer='adam',\n",
    "                     learning_rate= 0.0003)\n",
    "current_model.build_cnn()\n",
    "#current_model.fit(data_manager, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Note: All of the attacks, both PGD and FGSM are untargeted.\n",
    "    References:\n",
    "     - https://colab.research.google.com/github/andantillon/cleverhans/blob/master/tutorials/future/tf2/notebook_tutorials/mnist_fgsm_tutorial.ipynb#scrollTo=DlQ833TumOUC\n",
    "\"\"\"\n",
    "xTest = data_manager.X_test\n",
    "yTest = data_manager.y_test\n",
    "\n",
    "original_images = []\n",
    "original_labels = []\n",
    "for _ in range(20):\n",
    "    random_index = np.random.randint(xTest.shape[0])\n",
    "    original_images.append(xTest[random_index])\n",
    "    original_labels.append(data_manager.classes[yTest[random_index]])\n",
    "\n",
    "plot_images(5, 4, original_images, original_labels)   # original images and true labels plot\n",
    "\n",
    "# Attacking procedure starts here\n",
    "pgd_labels_pred = []\n",
    "pgd_images = []\n",
    "\n",
    "fgsm_labels_pred = []\n",
    "fgsm_images = []\n",
    "\n",
    "# Hyperparameters\n",
    "eps = 0.0313\n",
    "eta = 0.005\n",
    "k = 20\n",
    "\n",
    "# Attack for each image\n",
    "for image in original_images:\n",
    "    x_tensor = tf.convert_to_tensor(image.reshape((1,32,32,3)))  #reshape each original image\n",
    "    \n",
    "    # PGD attack\n",
    "    adv_image = projected_gradient_descent(current_model.get_model(), x_tensor, eps = eps, \n",
    "                                           eps_iter = eta , nb_iter= k, norm = np.inf, targeted = False)\n",
    "    adv_label_pred = current_model.predict(adv_image)\n",
    "    pgd_labels_pred.append(adv_label_pred[0])\n",
    "    pgd_images.append(np.reshape(adv_image, (32,32,3)))   #reshape back into proper image shape\n",
    "    \n",
    "    # FGSM attack\n",
    "    adv2_image = fast_gradient_method(current_model.get_model(), x_tensor, eps = eps, norm = np.inf, targeted = False)\n",
    "    adv2_label_pred = current_model.predict(adv2_image)\n",
    "    fgsm_labels_pred.append(adv2_label_pred[0])\n",
    "    fgsm_images.append(np.reshape(adv2_image, (32,32,3)))\n",
    "    \n",
    "# Map the labels to respective classes\n",
    "pgd_labels_classes = [data_manager.classes[pred] for pred in pgd_labels_pred]\n",
    "fgsm_labels_classes = [data_manager.classes[pred2] for pred2 in fgsm_labels_pred]\n",
    "\n",
    "plot_images(5, 4, pgd_images, pgd_labels_classes)   # pgd adversial plot \n",
    "plot_images(5, 4, fgsm_images, fgsm_labels_classes)   # fgsm adversial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy for each attack\n",
    "pgd_accuracy = accuracy_score(original_labels, pgd_labels_classes)\n",
    "fgsm_accuracy = accuracy_score(original_labels, fgsm_labels_classes)\n",
    "print(\"PGS accuracy: \"+ str(pgd_accuracy))\n",
    "print(\"FGSM accuracy: \"+ str(fgsm_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
